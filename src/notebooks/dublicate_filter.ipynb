{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import imagehash\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_images(\n",
    "    image_paths: List[Path],\n",
    "    threshold: int = 5\n",
    ") -> dict[str, List[Path]]:\n",
    "    \"\"\"\n",
    "    Группирует похожие изображения на основе хеша.\n",
    "    \n",
    "    :param image_paths: список путей к изображениям\n",
    "    :param threshold: максимальное расстояние между хешами (0-64)\n",
    "                     чем меньше, тем строже сравнение\n",
    "    :return: {representative_hash: [список похожих путей]}\n",
    "    \"\"\"\n",
    "    hashes = {}\n",
    "    groups = defaultdict(list)\n",
    "    \n",
    "    # Сначала собираем все хеши\n",
    "    for path in tqdm(image_paths, desc=\"Compute hashes\"):\n",
    "        try:\n",
    "            img = Image.open(path)\n",
    "            h = imagehash.phash(img)\n",
    "            hashes[path] = h\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка обработки {path}: {e}\")\n",
    "    \n",
    "    # Группируем похожие изображения\n",
    "    used_paths = set()\n",
    "    for path1, hash1 in tqdm(hashes.items(), desc=\"Grouping similar images\"):\n",
    "        if path1 in used_paths:\n",
    "            continue\n",
    "            \n",
    "        current_group = [path1]\n",
    "        for path2, hash2 in hashes.items():\n",
    "            if path2 not in used_paths and path1 != path2:\n",
    "                if hash1 - hash2 <= threshold:  # Расстояние Хемминга\n",
    "                    current_group.append(path2)\n",
    "        \n",
    "        if len(current_group) > 1:  # Только группы с похожими изображениями\n",
    "            for p in current_group:\n",
    "                used_paths.add(p)\n",
    "            # Используем hex-представление хэша как ключ\n",
    "            groups[str(hash1)].extend(current_group)\n",
    "    \n",
    "    return dict(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_move_duplicates(\n",
    "    image_paths: List[Path],\n",
    "    output_dir: Path,\n",
    "    threshold: int = 5,\n",
    "    min_group_size: int = 2\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Находит дубликаты в папке и перемещает их в подпапки output_dir.\n",
    "    \n",
    "    :param input_dir: Папка с изображениями для проверки\n",
    "    :param output_dir: Папка для сохранения групп дубликатов\n",
    "    :param threshold: Максимальное расстояние между хешами (0-64)\n",
    "    :param min_group_size: Минимальный размер группы для перемещения\n",
    "    \"\"\"\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir(parents=True)\n",
    "    \n",
    "    # Находим похожие изображения\n",
    "    groups = find_similar_images(image_paths=image_paths, threshold=threshold)\n",
    "    \n",
    "    # Перемещаем группы дубликатов\n",
    "    moved = 0\n",
    "    for group_num, (hash_val, paths) in enumerate(groups.items(), 1):\n",
    "        if len(paths) >= min_group_size:\n",
    "            # Первый файл в группе считаем оригиналом (не перемещаем)\n",
    "            original = paths[0]\n",
    "            filename_without_suffix = original.name.replace(original.suffix, '')\n",
    "            group_dir = output_dir / f\"duplicates_{filename_without_suffix}_{group_num}\"\n",
    "            group_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # Перемещаем дубликаты\n",
    "            for duplicate in paths[1:]:\n",
    "                shutil.move(duplicate, group_dir / duplicate.name)\n",
    "                # print(f\"Дубликат → {group_dir.name}/{duplicate.name}\")\n",
    "                moved += 1\n",
    "    \n",
    "    return moved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Директория: /home/little-garden/CodeProjects/InteriorClass/src/notebooks\n",
      "data_dir: /home/little-garden/CodeProjects/InteriorClass/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute hashes: 100%|██████████| 54617/54617 [01:34<00:00, 574.96it/s]\n",
      "Grouping similar images: 100%|██████████| 54617/54617 [1:22:30<00:00, 11.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 | Moved 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "current_dir = Path.cwd()\n",
    "print(f\"Директория: {current_dir}\")\n",
    "data_dir = current_dir.parent.parent / \"data\"\n",
    "print(f\"data_dir: {data_dir}\")\n",
    "\n",
    "dataset_dir = data_dir / \"interior_dataset\"\n",
    "all_dataset_images = []\n",
    "for path in sorted(dataset_dir.iterdir()):\n",
    "    if path.is_dir():\n",
    "        image_paths = sorted(path.iterdir())\n",
    "        all_dataset_images.extend(image_paths)\n",
    "\n",
    "moved = find_and_move_duplicates(image_paths=all_dataset_images, output_dir=dataset_dir / \"dublicates\")\n",
    "print(f\"{path.name} | Moved {moved}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
